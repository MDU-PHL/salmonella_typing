---
title: "MMS136 Limit of detection report"
author:
    - "MDU PHL"
date: "`r format(Sys.time(), '%d %B %Y')`"
params:
   rmd: "report.Rmd"
output:
  pdf_document:
  highlight: tango
  number_sections: no
  theme: default
  toc: yes
  toc_depth: 3
editor_options: 
  chunk_output_type: console
---

```{r, load_libs, message=FALSE, error=FALSE, comment=FALSE, echo=FALSE}
library(tidyverse)
library(readxl)
library(glue)
library(ggplot2)
library(kableExtra)
library(openxlsx)
library(knitr)
testing = TRUE
asms <- c('spades', 'skesa', 'shovill')
knitr::opts_chunk$set(cache=TRUE, message=FALSE, error=FALSE, comment=FALSE, echo=FALSE, warning=TRUE)
```

```{r, functions}
check_positive_control <- function(tab) {
  stat <- tab %>%
      filter(SEQID == '9999-99999-1') %>%
      pull(STATUS)
  return(stat == 'PASS')
}

get_file <- function(pattern, file_list) {
  ix <- which(grepl(pattern = pattern, file_list))
  return(file_list[ix])
}

load_data <- function(skobj, asm){
  sistr_res <- get_file(asm, skobj@input[['sistr_res']])
  sistr_metad <- get_file(asm, skobj@input[['sistr_metad']])
  res <- read_xlsx(sistr_res, sheet='ALL')
  metad <- read_tsv(sistr_metad)
  
  res_raw <- res %>%
    select(-ID) %>%
    left_join(metad, c("SEQID" = "SEQID"))

  res_clean <- res_raw %>%
    select(ID, SEQID, assembler, depth, rep, STATUS, num_seqs, sum_len, min_len, max_len, N50) %>%
    rename(DEPTH = depth) %>%
    mutate(POS_CONTROL_PASS = check_positive_control(.)) %>%
    filter(SEQID != '9999-99999-1') %>%
    mutate(PROBABILITY_PASS = if_else(STATUS == 'PASS', 1, 0))
  
  return(list(raw = res_raw,
              clean = res_clean))
}

if(testing) {
  base_dir = 'validation/limitOfDetection/data'
  setClass('sk', representation(input = 'list'))
  skobj <- new(Class = 'sk', input = list(
    'sistr_res' = sapply(asms, function(asm) file.path(base_dir, glue('SISTR_LIMS_{asm}.xlsx'))),
    'sistr_metad' = sapply(asms, function(asm) file.path(base_dir, glue('sistr_input_{asm}.txt')))
  ))
}
```


```{r, load_data}

dat <- lapply(asms, function(asm) load_data(skobj, asm))

clean_dat <- bind_rows(lapply(dat, function(d) d$clean))
raw_dat <- bind_rows(lapply(dat, function(d) d$raw))

wb <- createWorkbook()
addWorksheet(wb, 'LOD_MMS136')
writeDataTable(wb, 'LOD_MMS136', x = raw_dat)
saveWorkbook(wb, file="lod_mm136.xlsx")

plot_dat <- clean_dat %>%
  group_by(assembler, ID, DEPTH) %>%
  summarise(TOTAL_PASS = sum(PROBABILITY_PASS),
            PROP_PASS = sum(PROBABILITY_PASS)/n()) %>%
  ggplot(aes(x = DEPTH, y = PROP_PASS)) +
    geom_point() +
    xlab("Depth") +
    ylab("Proportion Passed") +
    facet_grid(ID~assembler)

summ_dat <- clean_dat %>%
  group_by(DEPTH, assembler) %>%
  summarise(`N` = n(),
            `Total Pass` = sum(PROBABILITY_PASS),
            `Proportion Pass` = sum(PROBABILITY_PASS)/n()) %>%
  arrange(assembler, DEPTH) %>%
  rename(Depth = DEPTH,
         Assembler = assembler)
```

```{r, model, results='hide'}
library(brms)
library(tidybayes)
library(modelr)
library(pander)
m1 <- brm(formula = PROBABILITY_PASS~DEPTH+assembler+ID,
          family = 'bernoulli',
          data=clean_dat,
          silent = T, refresh=0)
```


```{r}
miss_dat <- raw_dat %>%
  select('ID', 'assembler', 'depth', 'h1', 'h2', 'o_antigen', 'serogroup') %>%
  filter(!is.na(ID)) %>%
  mutate(h1_c = h1 == 'g,m',
         oa_c = o_antigen == '1,9,12',
         serog_c = serogroup == 'D1')

miss_dat %>%
  group_by(depth, assembler) %>%
  summarise(PROP = sum(serog_c)/n()) %>%
  ggplot(aes(x = depth, y = PROP, col = assembler)) +
  geom_point()

m_serog <- brm(serog_c ~ depth + assembler + ID, data = miss_dat, family = 'bernoulli')
summary(m_serog)
marginal_effects(m_serog, 'depth:assembler')

m_oa <- brm(oa_c ~ depth + assembler + ID, data = miss_dat, family = 'bernoulli')
```


## Experiment setup

A limit of detection experiment to determine the minimum depth of coverage needed for
correct inference of *Salmonella* serotype using MDU's MMS136 SOP.

* Number of samples included: `r clean_dat %>% pull(ID) %>% unique() %>% length()`
* Number of depth levels considered: `r clean_dat %>% pull(DEPTH) %>% unique() %>% length()`
* Depth levels considered: `r clean_dat %>% pull(DEPTH) %>% unique() %>% sort() %>% str_c(., collapse = ", ")`
* Number of replicates of each sample/depth combination: `r clean_dat %>% pull(rep) %>% unique() %>% max()`
* Assemblers tested: `r asms %>%  str_c(., collapse = ", ")`

## Analytical Methods

Reads for each sample were randomly subsampled to the required depth. The reads were then 
assembled with each of the stated assemblers. The assemblies were then analysed with the 
MMS136 pipeline. Combinations that were found to be a `PASS` were deemed successful, 
any other results was considered a failure. A simple Bayesian logistic model was fitted to the
data with response variable being 0/1 representing fail/success MMS136 pipeline, and
the predictor variables were: `depth`, `assembler`, and `sample ID`. 

We report the minimum depth required to have a 95% probability that the success
rate is $\ge0.90$ for each assembler.

## Results

```{r, summary_table}
clean_dat %>%
  data_grid(DEPTH, assembler, ID) %>%
  add_fitted_draws(m1) %>%
  group_by(DEPTH, assembler) %>%
  summarise(prob_9 = sum(.value > 0.90)/n()) %>%
  filter(prob_9 > 0.95) %>%
  arrange(prob_9) %>%
  group_by(assembler) %>%
  summarise(min_d = min(DEPTH)) %>%
  rename(Assembler = assembler,
         `Min Depth` = min_d) %>%
  kable(format = 'latex',
        caption = "Minimum depth required to a 95\\% probability that the success rate is at least 0.90 (missing assemblers indicate the assembler never met the minimum requirements).", booktabs = T)  %>%
kable_styling(latex_options =c("striped", "hold_position"))
```

```{r, marginals, fig.cap="Posterior probability of success given depth of coverage and assembler."}
marginal_effects(m1, 'DEPTH:assembler')
```

```{r, sum}
summ_dat %>%
  kable(format = 'latex',
        caption = 'Summary raw data',
        booktabs = T) %>%
  kable_styling(latex_options =c("striped", "hold_position"))
```

